{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import psycopg2\n",
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../'))  # add the current module so that we can import the utils file\n",
    "from tools.utils import get_top_keywords_for_query, create_df_for_query\n",
    "\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import collections as mc\n",
    "import matplotlib.ticker as plticker\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(user=\"lvs215\",\n",
    "                                   password=\"\",\n",
    "                                   host=\"127.0.0.1\",\n",
    "                                   port=\"12777\",\n",
    "                                   database=\"aip\")\n",
    "start_year = 2011  # inclusive\n",
    "end_year = 2020  # inclusive\n",
    "num_keywords = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_keyword_graph(keyword_ranks_per_year_dict):\n",
    "    # Get all unique keywords and give them their own array for points.\n",
    "    keyword_number_dict = dict()\n",
    "    count = 0\n",
    "    points = []\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for keyword in keyword_ranks_per_year_dict[year]:\n",
    "            if keyword not in keyword_number_dict:\n",
    "                points.append([[], []])\n",
    "                keyword_number_dict[keyword] = count\n",
    "                count += 1\n",
    "\n",
    "    num_lines = len(keyword_number_dict.keys())\n",
    "    print(\"Number of unique keywords: {}\".format(num_lines))\n",
    "    print(keyword_number_dict)\n",
    "    \n",
    "    # Create a color map and generate colors equal to the number of unique keywords we want to track\n",
    "    cmap = get_cmap(len(keyword_number_dict.keys()))\n",
    "    c = [cmap(i) for i in range(len(keyword_number_dict.keys()))]\n",
    "    \n",
    "    # For each keyword, track it's rank throughout the years\n",
    "    for keyword, line_array_number in keyword_number_dict.items():\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            # The horizontal position is the year, offset by the start_year\n",
    "            horizontal_position = year - start_year\n",
    "            \n",
    "            # The vertical position is the inverse of its rank -- we want #1 to be at the top of the figure\n",
    "            if keyword in keyword_ranks_per_year_dict[year]:\n",
    "                vertical_position = abs(keyword_ranks_per_year_dict[year].index(keyword) - num_keywords)\n",
    "            else:\n",
    "                vertical_position = 0  # The graph starts at 0, this is the bottom rank.\n",
    "                            \n",
    "            # Add a point for the combination of (position (horizontal axis), inversed rank (vertical axis))\n",
    "            points[keyword_number_dict[keyword]][0].append(horizontal_position)\n",
    "            points[keyword_number_dict[keyword]][1].append(vertical_position)\n",
    "\n",
    "    # Create line segments from points, taken from https://matplotlib.org/examples/pylab_examples/multicolored_line.html\n",
    "    lines = []\n",
    "    for x, y in points:  # For each pair of coodinate, create a segment. Then add all segments as separate lines \n",
    "        transposed_points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "        lines.extend(np.concatenate([transposed_points[:-1], transposed_points[1:]], axis=1))\n",
    "                          \n",
    "    line_widths = []\n",
    "    colors = []\n",
    "    # Now, we can control the color and thickness of each line separately as each segment is a line\n",
    "    # Matplotlib doesn't allow a segment within a line to be changed in e.g. thickness :(\n",
    "    for i in range(num_lines):\n",
    "        # We know that each \"actual trend line\" now consists of (end_year - start_year) lines\n",
    "        line_widths.extend([3] * (end_year - start_year - 1) + [3])  # make the last line thicker\n",
    "        colors.extend([c[i]] * (end_year - start_year))  # Color all line segments the same that belong to the same keyword\n",
    "    \n",
    "    lc = mc.LineCollection(lines, colors=colors, linewidths=line_widths)\n",
    "                   \n",
    "    horizontal_labels = [x for x in range(start_year, end_year + 1)]\n",
    "    vertical_labels =  [\"<{}\".format(num_keywords)] + [i for i in range(num_keywords, 0, -1)]\n",
    "    \n",
    "    #print(horizontal_labels)\n",
    "    #print(vertical_labels)\n",
    "    #print(c)\n",
    "    #print(line_widths)\n",
    "    \n",
    "    fig, ax = pl.subplots(figsize=(12,8))\n",
    "    ax.autoscale()\n",
    "    ax.set_xlim(-0.2, end_year - start_year + 0.2)  # Add a small amount so that the lines are better visible at the edges\n",
    "    ax.set_ylim(-0.4, num_keywords + 0.4)  # Add a small amount so that the lines are better visible at the edges\n",
    "    ax.set_xticks(np.arange(0, end_year - start_year + 1, 1))\n",
    "    ax.set_yticks(np.arange(0, num_keywords + 1, 1))\n",
    "    ax.set_xticklabels(horizontal_labels, fontsize=12)\n",
    "    ax.set_yticklabels(vertical_labels, fontsize=12)\n",
    "    ax.add_collection(lc)\n",
    "    \n",
    "    ax.set_xlabel(\"Year\", fontsize=18)\n",
    "    ax.set_ylabel(\"Rank\", fontsize=18)\n",
    "    \n",
    "    # For visibility, we add markers at the ends of each segment.\n",
    "    marker_shapes = ['o', 'P', 'D', 'v', '^', '<', '>', 'X', '*', 'p', 'd', 'x', '+', '1', '2', '3', '4',]\n",
    "    marker_size = 8\n",
    "    for keyword, array_index in keyword_number_dict.items():\n",
    "        x = points[array_index][0]\n",
    "        y = points[array_index][1]\n",
    "        color = [c[array_index]] * len(x)\n",
    "        marker = marker_shapes[array_index % len(marker_shapes)]\n",
    "\n",
    "        ax.scatter(x, y, c=color, marker=marker, s=60)\n",
    "    \n",
    "    # code based on https://stackoverflow.com/questions/19877666/add-legends-to-linecollection-plot\n",
    "    def make_proxy(line_number, color_map, **kwargs):\n",
    "        color = color_map(line_number)\n",
    "        return Line2D([0, 1], [0, 1], color=color, **kwargs)\n",
    "    \n",
    "    # Add a custom legend\n",
    "    proxies = [make_proxy(array_index, cmap, linewidth=1, marker= marker_shapes[array_index % len(marker_shapes)], markersize=marker_size) for array_index in keyword_number_dict.values()]\n",
    "    ax.legend(proxies, keyword_number_dict.keys(), bbox_to_anchor=(1, 1.017), fontsize=13)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_keyword_graph_emphasize_most_recent_top_10(keyword_ranks_per_year_dict, add_flat_lines=False):\n",
    "    # Get all unique keywords and give them their own array for points.\n",
    "    keyword_number_dict = dict()\n",
    "    count = 0\n",
    "    lines = []\n",
    "    keyword_to_color = dict()\n",
    "    \n",
    "    for year in range(start_year, end_year + 1):\n",
    "        for keyword in keyword_ranks_per_year_dict[year]:\n",
    "            if keyword not in keyword_number_dict:\n",
    "                lines.append([])\n",
    "                keyword_number_dict[keyword] = count\n",
    "                count += 1\n",
    "\n",
    "    num_lines = len(keyword_number_dict.keys())\n",
    "    print(\"Number of unique keywords: {}\".format(num_lines))\n",
    "    print(keyword_number_dict)\n",
    "    \n",
    "    # Create a color map and generate colors equal to the number of unique keywords we want to track\n",
    "    cmap = get_cmap(len(keyword_number_dict.keys()))\n",
    "    c = [cmap(i) for i in range(num_lines)]\n",
    "    \n",
    "    # For each keyword, track it's rank throughout the years\n",
    "    for keyword in keyword_number_dict.keys():\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            # The horizontal position is the year, offset by the start_year\n",
    "            horizontal_position = year - start_year\n",
    "            \n",
    "            # The vertical position is the inverse of its rank -- we want #1 to be at the top of the figure\n",
    "            if keyword in keyword_ranks_per_year_dict[year]:\n",
    "                vertical_position = abs(keyword_ranks_per_year_dict[year].index(keyword) - num_keywords)\n",
    "            else:\n",
    "                vertical_position = 0  # The graph starts at 0, this is the bottom rank.\n",
    "                            \n",
    "            # Add a point for the combination of (position (horizontal axis), inversed rank (vertical axis))\n",
    "            lines[keyword_number_dict[keyword]].append((horizontal_position, vertical_position))\n",
    "            # Add a fake point halfway through the year where so that we create a flat per point.\n",
    "            # This is done to add some stability in the graph to improve readability.\n",
    "            # Do not add this point at the end, though.\n",
    "            if year != end_year and add_flat_lines:\n",
    "                lines[keyword_number_dict[keyword]].append((horizontal_position + .5, vertical_position))\n",
    "        \n",
    "    line_widths = []\n",
    "    colors = []\n",
    "    diffrentiating_colors = [\n",
    "        \"#e41a1c\",\n",
    "        \"#377eb8\",\n",
    "        \"#4daf4a\",\n",
    "        \"#984ea3\",\n",
    "        \"#ff7f00\",\n",
    "        \"#ffff00\",\n",
    "        \"#a65628\",\n",
    "        \"#f781bf\",\n",
    "        \"#000000\",\n",
    "        \"#a6cee3\",\n",
    "        \"#999999\",\n",
    "    ]\n",
    "    # Now, we can control the color and thickness of each line separately as each segment is a line\n",
    "    # Matplotlib doesn't allow a segment within a line to be changed in e.g. thickness :(\n",
    "    for keyword in keyword_number_dict.keys():\n",
    "        rank_in_last_year = keyword_ranks_per_year_dict[end_year].index(keyword) if keyword in keyword_ranks_per_year_dict[end_year] else num_keywords + 1\n",
    "        if rank_in_last_year >= num_keywords: # >= because the rank is 0-based\n",
    "            line_widths.append(2)  # Not a top-10 line, so not thick\n",
    "            colors.append('grey')  # Not a top-10 line, so grey color.\n",
    "            keyword_to_color[keyword] = 'grey'\n",
    "        else:\n",
    "            color = diffrentiating_colors[rank_in_last_year % len(diffrentiating_colors)]\n",
    "            line_widths.append(13 - rank_in_last_year)  # The most important keyword has the thickest line\n",
    "            colors.append(color)  # Set the color\n",
    "            keyword_to_color[keyword] = color\n",
    "    \n",
    "    lc = mc.LineCollection(lines, colors=colors, linewidths=line_widths)\n",
    "                   \n",
    "    horizontal_labels = [x for x in range(start_year, end_year + 1)]\n",
    "    vertical_labels =  [\"<{}\".format(num_keywords)] + [i for i in range(num_keywords, 0, -1)]\n",
    "    \n",
    "    #print(horizontal_labels)\n",
    "    #print(vertical_labels)\n",
    "    #print(c)\n",
    "    #print(line_widths)\n",
    "    \n",
    "    fig, ax = pl.subplots(figsize=(24,8))\n",
    "    #ax.autoscale()\n",
    "    ax.set_xlim(-0.2, end_year - start_year + 0.2)  # Add a small amount so that the lines are better visible at the edges\n",
    "    ax.set_ylim(-0.4, num_keywords + 0.4)  # Add a small amount so that the lines are better visible at the edges\n",
    "    ax.set_xticks(np.arange(0, end_year - start_year + 1, 1))\n",
    "    ax.set_yticks(np.arange(0, num_keywords + 1, 1))\n",
    "    ax.set_xticklabels(horizontal_labels, fontsize=32)\n",
    "    ax.set_yticklabels(vertical_labels, fontsize=32)\n",
    "    ax.add_collection(lc)\n",
    "    \n",
    "    ax.set_xlabel(\"Year\", fontsize=40)\n",
    "    ax.set_ylabel(\"Rank\", fontsize=40)\n",
    "    \n",
    "    def sort_func(x):\n",
    "        return keyword_ranks_per_year_dict[end_year].index(x[0]) if x[0] in keyword_ranks_per_year_dict[end_year] else num_keywords + 1\n",
    "    sorted_items_for_markers = sorted(keyword_number_dict.items(), key=sort_func)\n",
    "    \n",
    "    # For visibility, we add markers at the ends of each segment.\n",
    "    marker_shapes = ['o', 'P', 'D', 'v', '^', '<', '>', 'X', '*', 'p', 'd', 'x', '+', '1', '2', '3', '4',]\n",
    "    marker_size = 8\n",
    "    for index, (keyword, array_index) in enumerate(sorted_items_for_markers):\n",
    "        x = [x[0] for x in lines[array_index]]\n",
    "        y = [x[1] for x in lines[array_index]]\n",
    "        color = [keyword_to_color[keyword]] * len(x)\n",
    "        marker = marker_shapes[index % len(marker_shapes)]\n",
    "\n",
    "        ax.scatter(x, y, c=color, marker=marker, s=60)\n",
    "    \n",
    "    # code based on https://stackoverflow.com/questions/19877666/add-legends-to-linecollection-plot\n",
    "    def make_proxy(color, **kwargs):\n",
    "        return Line2D([0, 1], [0, 1], color=color, **kwargs)\n",
    "    \n",
    "    # Add a custom legend\n",
    "    proxies = [make_proxy(keyword_to_color[keyword], linewidth=1, marker= marker_shapes[index % len(marker_shapes)], markersize=marker_size) for index, (keyword, _) in enumerate(sorted_items_for_markers)]\n",
    "    legend = ax.legend(proxies, [x[0] for x in sorted_items_for_markers], ncol=min(3, math.ceil(len(keyword_number_dict.keys())/12.0)), bbox_to_anchor=(1, 1.017), fontsize=28, bbox_transform=ax.transAxes, markerscale=2)\n",
    "    fig.tight_layout()\n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct the corpus dataframe that we want to run TF-IDF against\n",
    "corpus_query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM publications \n",
    "    WHERE year BETWEEN %s AND %s\"\"\"\n",
    "corpus_df = create_df_for_query(conn, corpus_query, [start_year, end_year])\n",
    "\n",
    "# generate_keyword_graph(keywords_per_year)\n",
    "#generate_keyword_graph_emphasize_most_recent_top_10(keywords_per_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "queries = [\n",
    "# Workflow communities - 1\n",
    "(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM publications \n",
    "    WHERE year = %s\n",
    "    AND (title ILIKE %s OR abstract ILIKE %s) \n",
    "    AND (title ILIKE %s OR abstract ILIKE %s)\n",
    "    \"\"\",\n",
    "    \"workflow-community\",\n",
    "    \"collaboration-network-workflow-scheduling_aip.gexf\",\n",
    "    [\"%workflow%\", \"%workflow%\", '%schedul%', '%schedul%']\n",
    "),\n",
    "\n",
    "# # Workflow formalisms - 2\n",
    "# (\n",
    "#     \"\"\"\n",
    "#     SELECT *\n",
    "#     FROM publications\n",
    "#     WHERE year = %s\n",
    "#     AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#     AND (\n",
    "#         (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#         OR (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#     )\n",
    "#     \"\"\",\n",
    "#     \"workflow-formalism-community\",\n",
    "#     \"collaboration-network-workflow-formalisms_aip.gexf\",\n",
    "#     [\"%workflow%\", \"%workflow%\", \"%formalism%\", \"%formalism%\", \"%language%\", \"%language%\"]\n",
    "# ),\n",
    "    \n",
    "# # Workflow allocation - 3\n",
    "# (\n",
    "#     \"\"\"\n",
    "#     SELECT *\n",
    "#     FROM publications\n",
    "#     WHERE year = %s\n",
    "#     AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#     AND (\n",
    "#         (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#         OR (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#         OR (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#     )\n",
    "#     \"\"\",\n",
    "#     \"workflow-allocation-community\",\n",
    "#     \"collaboration-network-workflow-allocation_aip.gexf\",\n",
    "#     [\"%workflow%\", \"%workflow%\", \"%allocat%\", \"%allocat%\", \"%schedul%\", \"%schedul%\", \"%plan%\", \"%plan%\"]\n",
    "# ),\n",
    "\n",
    "    \n",
    "# # Resource provisioning communities - 4\n",
    "# (\n",
    "#     \"\"\"\n",
    "#     SELECT *\n",
    "#     FROM publications\n",
    "#     WHERE year = %s\n",
    "#     AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#     AND (\n",
    "#         lower(title) ILIKE %s OR lower(abstract) ILIKE %s\n",
    "#         OR lower(title) ILIKE %s OR lower(abstract) ILIKE %s\n",
    "#     )\n",
    "#     \"\"\",\n",
    "#     \"resource-provisioning-community\",\n",
    "#     \"collaboration-network-resource-provisioning_aip.gexf\",\n",
    "#     [\"%workflow%\", \"%workflow%\", \"%provision%\", \"%provision%\", \"%autoscal%\", \"%autoscal%\"]\n",
    "# ),\n",
    "\n",
    "# # applications and services - 5\n",
    "# (\n",
    "#     \"\"\"\n",
    "#     SELECT *\n",
    "#     FROM publications\n",
    "#     WHERE year = %s\n",
    "#     AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#     AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "#     \"\"\",\n",
    "#     \"applications-and-services-community\",\n",
    "#     \"collaboration-network-applications-and-services-community_aip.gexf\",\n",
    "#     [\"%cloud%\", \"%cloud%\", \"%service%\", \"%service%\"]\n",
    "# ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords_per_year = dict()\n",
    "custom_stopwords_for_query = set([\"resource\", \"execution\", \"scientific\", \"service\", \"management\", \"based\", \n",
    "                              \"computing\", \"schedule\", \"approach\", \"different\", \"distributed\", \"science\", \n",
    "                              \"system\", \"intensive\", \"aware\", \"executing\", \"science\", \"file\", \"characteristic\", \n",
    "                              \"complex\", \"bi\", \"proposed\", \"transfer\", \"hybrid\", \"directed\", \"constraint\", \n",
    "                              \"constrained\", \"multi\", \"multiple\", \"scientist\", \"tolerance\"])\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM publications \n",
    "    WHERE year = %s \n",
    "    AND (title like '%workflow%' or abstract like '%workflow%') \n",
    "    AND (title like '%schedul%' or abstract like '%schedul%')\"\"\"\n",
    "    keywords = [x for x in get_top_keywords_for_query(conn, corpus_df, query, 50, [year]) if x not in custom_stopwords_for_query]\n",
    "    keywords_per_year[year] = keywords[:num_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_keyword_graph(keywords_per_year)\n",
    "\n",
    "generate_keyword_graph_emphasize_most_recent_top_10(keywords_per_year)\n",
    "generate_keyword_graph_emphasize_most_recent_top_10(keywords_per_year, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell runs all the queries defiend above\n",
    "custom_stopwords_for_query = set([\"resource\", \"execution\", \"scientific\", \"service\", \"management\", \"based\", \n",
    "                              \"computing\", \"schedule\", \"approach\", \"different\", \"distributed\", \"science\", \n",
    "                              \"system\", \"intensive\", \"aware\", \"executing\", \"science\", \"file\", \"characteristic\", \n",
    "                              \"complex\", \"bi\", \"proposed\", \"transfer\", \"hybrid\", \"directed\", \"constraint\", \n",
    "                              \"constrained\", \"multi\", \"multiple\", \"scientist\", \"tolerance\", \"overall\", \"driven\",\n",
    "                                 \"improve\", \"make\", \"continue\", \"popularity\", \"extended\", \"problem\", \"predefined\",\n",
    "                                 \"using\", \"ideal\", \"extension\", \"composition\", \"abstraction\", \"level\", \"processing\",\n",
    "                                 \"activity\", \"structured\", \"use\", \"changing\", \"easy\", \"achieved\", \"permit\",\n",
    "                                 \"involved\", \"remote\", \"oriented\", \"managing\", \"crucial\", \"describes\", \"modeled\",\n",
    "                                 \"executed\", \"expressed\", \"finding\", \"existing\", \"program\", \"discus\", \"underlying\",\n",
    "                                 \"increasingly\", \"exploration\", \"large\", \"suggest\", \"describe\", \"process\", \"work\",\n",
    "                                 \"complexity\", \"authored\", \"facing\", \"two\", \"taken\", \"posit\", \"usage\", \"strategy\", \n",
    "                                  \"various\", \"result\", \"complicated\", \"turning\", \"knowledge\", \"achieve\", \"set\", \n",
    "                                  \"review\", \"diverse\", \"available\", \"bed\", \"drawn\", \"collaborative\", \"charm\", \n",
    "                                  \"definition\", \"technique\", \"would\", \"submission\", \"effective\", \"juju\", \n",
    "                                  \"specific\", \"used\", \"followed\", \"hive\", \"20\", \"within\", \"paper\", \"related\", \"research\",\n",
    "                                 \"many\", \"support\", \"create\", \"look\", \"express\", \"declaration\", \"properly\", \"ha\",\n",
    "                                 \"iaa\", \"grp\", \"well\", \"aim\", \"option\", \"solution\", \"select\", \"targeting\", \"description\",\n",
    "                                 \"incremental\", \"scale\", \"challenge\", \"compiled\", \"ease\", \"rest\", \"scripting\", \"structure\",\n",
    "                                 \"implementation\", \"integrate\", \"red\", \"one\", \"new\", \"dealing\", \"cover\", \"toolkitas\", \"elba\",\n",
    "                                 \"wed\", \"first\", \"four\", \"back\", \"specified\", \"moved\", \"analysis\"])\n",
    "\n",
    "for query, community_name, _, query_args in queries:\n",
    "    print(community_name)\n",
    "    keywords_per_year = dict()\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        keywords = [x for x in get_top_keywords_for_query(conn, corpus_df, query, 50, [year, *query_args]) if x not in custom_stopwords_for_query]\n",
    "        keywords_per_year[year] = keywords[:num_keywords]\n",
    "    fig = generate_keyword_graph_emphasize_most_recent_top_10(keywords_per_year, True)\n",
    "    date_time = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "    fig.savefig(\"{}_{}.pdf\".format(community_name, date_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "generate_keyword_graph_emphasize_most_recent_top_10(keywords_per_year, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
