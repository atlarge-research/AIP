{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lfdversluis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lfdversluis/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "# Add the main module and venue_mappings modules to path so we can import them\n",
    "sys.path.insert(0, os.path.abspath('../venue_mappings'))\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "\n",
    "from util import iterload_file_lines\n",
    "from tools.utils import get_top_keywords_for_query\n",
    "from venue_mappings.venue_map import VenueMapper\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = sqlite3.connect('community_aminer_dblp_v11.db')\n",
    "cursor = db.cursor()\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS publications\n",
    "                        (id VARCHAR(64) NOT NULL,\n",
    "                        venue VARCHAR(16),\n",
    "                        year INTEGER,\n",
    "                        volume VARCHAR(8),\n",
    "                        title VARCHAR(512),\n",
    "                        doi VARCHAR(128),\n",
    "                        abstract TEXT,\n",
    "                        citations INTEGER,\n",
    "                        PRIMARY KEY (id)\n",
    "                        );''')\n",
    "\n",
    "cursor.execute('''CREATE INDEX IF NOT EXISTS ind_title\n",
    "                                ON publications (title);''')\n",
    "\n",
    "cursor.execute('''CREATE INDEX IF NOT EXISTS ind_abstract\n",
    "                                ON publications (abstract);''')\n",
    "\n",
    "cursor.execute('''CREATE INDEX IF NOT EXISTS ind_venue\n",
    "                                ON publications (venue);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS authors\n",
    "                        (id VARCHAR(64) NOT NULL,\n",
    "                        name VARCHAR(128)\n",
    "                        );''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS author_publication\n",
    "                        (author VARCHAR(64) NOT NULL,\n",
    "                        publication_id VARCHAR(64) NOT NULL\n",
    "                        );''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS collaborations\n",
    "                        (author VARCHAR(64) NOT NULL,\n",
    "                        co_author VARCHAR(64) NOT NULL\n",
    "                        );''')\n",
    "\n",
    "cursor.execute('''CREATE UNIQUE INDEX IF NOT EXISTS author_collaboration_pair\n",
    "                        ON collaborations (author, co_author);''')\n",
    "\n",
    "cursor.execute('''CREATE UNIQUE INDEX IF NOT EXISTS author_publication_pair\n",
    "                        ON author_publication (author, publication_id);''')\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_article(id, venue, year, volume, title, doi, abstract, citations):\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO publications (id, venue, year, volume, title, doi, abstract, citations) VALUES(?, ?, ?, ?, ?, ?, ?, ?)\",\n",
    "                                (id, venue, year, volume, title, doi, abstract, citations))\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_author(id, name):\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO authors (id, name) VALUES(?, ?)\", (id, name))\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_author_publication(author_id, publication_id):\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO author_publication (author, publication_id) VALUES(?, ?)\", (author_id, publication_id))\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_author_relation(author, co_author):\n",
    "    cursor.execute(\"INSERT OR IGNORE INTO collaborations (author, co_author) VALUES(?, ?)\", (author, co_author))\n",
    "    db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4ab57833d663>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Expects the data and format of V11 as outlined on https://aminer.org/citation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/media/lfdversluis/datastore/aminer/Aminer-DBLP-author-relationship+citation-dataset/dblp_papers_v11.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ISO-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnetwork_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterload_file_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"venue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"authors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_citation\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# Should never occur, but you never know...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/AIP/util.py\u001b[0m in \u001b[0;36miterload_file_lines\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miterload_file_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mjson_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aip/lib/python3.7/encodings/latin_1.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatin_1_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run this cell only if you need to create or update the contents of the database.\n",
    "\n",
    "venue_mapper = VenueMapper()\n",
    "# Expects the data and format of V11 as outlined on https://aminer.org/citation\n",
    "with open(\"/media/lfdversluis/datastore/aminer/Aminer-DBLP-author-relationship+citation-dataset/dblp_papers_v11.txt\", mode=\"r\", encoding=\"ISO-8859-1\") as network_file:\n",
    "    for article in iterload_file_lines(network_file):\n",
    "        if any(a not in article for a in [\"venue\", \"authors\", \"n_citation\"]):\n",
    "            continue  # Should never occur, but you never know...\n",
    "\n",
    "        if \"raw\" not in article[\"venue\"]:\n",
    "            continue  # Sometimes there is just the field \"id\" in the venue object.\n",
    "            \n",
    "        try:\n",
    "            venue = article[\"venue\"][\"raw\"]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(article)\n",
    "        \n",
    "        venue = venue_mapper.get_abbreviation(venue)\n",
    "        if venue is None:  # We only consider papers in the system community, i.e., identified by the venue mapper.\n",
    "            continue\n",
    "\n",
    "        authors = article[\"authors\"]\n",
    "        n_citations = article[\"n_citation\"]\n",
    "        article_id = article[\"id\"]\n",
    "        article_volume = article[\"volume\"] if \"volume\" in article else \"\"\n",
    "        article_year = article[\"year\"] if \"year\" in article else 0\n",
    "        article_abstract = article[\"abstract\"] if \"abstract\" in article else 0\n",
    "        article_doi = article[\"doi\"] if \"doi\" in article else 0\n",
    "        article_title = article[\"title\"] if \"title\" in article else 0\n",
    "        \n",
    "        insert_article(id=article_id, venue=venue, year=article_year, volume=article_volume, title=article_title, doi=article_doi, abstract=article_abstract, citations=n_citations)\n",
    "        \n",
    "\n",
    "        for author in authors:\n",
    "            author_id = author[\"id\"]\n",
    "            author_name = author[\"name\"] if \"name\" in author else \"\"\n",
    "            \n",
    "            insert_author_publication(author_id, article_id)\n",
    "            \n",
    "            # Insert the author\n",
    "            insert_author(id=author_id, name=author_name)\n",
    "\n",
    "            for co_author in authors:\n",
    "                co_author_id = co_author[\"id\"]\n",
    "                co_author_name = co_author[\"name\"] if \"name\" in co_author else \"\"\n",
    "                \n",
    "                if author_id == co_author_id:\n",
    "                    continue\n",
    "                \n",
    "                # Put a relation of (smallest id, larger id) to only add an edge once later.\n",
    "                # Doing this ensures we do not add a relationship more than once.\n",
    "                if author_id < co_author_id:\n",
    "                    insert_author_relation(author_id, co_author_id)\n",
    "                else:\n",
    "                    insert_author_relation(co_author_id, author_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_network_for_paper_query(article_query, file_name):\n",
    "    \"\"\"\n",
    "    This function generates a network collaboration graph based on a query provided.\n",
    "    \n",
    "    query: The query provided MUST select all publication ids that you want to build the network graph from.\n",
    "    An example: \"SELECT id FROM publications WHERE year BETWEEN 2010 AND 2019\"\n",
    "    file_name: The file name that should be written to.\n",
    "    \"\"\"\n",
    "    \n",
    "    query = \"SELECT a.id, a.name FROM authors a INNER JOIN author_publication ap ON a.id = ap.author WHERE ap.publication_id IN ({})\".format(article_query)\n",
    "    query_result = cursor.execute(query)\n",
    "\n",
    "    g = nx.Graph()\n",
    "    for row in query_result:\n",
    "        author_id = row[0]\n",
    "        author_name = row[1]\n",
    "        g.add_node(author_id, label=author_name)\n",
    "\n",
    "    query = \"SELECT DISTINCT c.author, c.co_author FROM collaborations c INNER JOIN author_publication ap ON c.author == ap.author OR c.co_author == ap.author WHERE ap.publication_id IN ({})\".format(article_query)\n",
    "    query_result = cursor.execute(query)\n",
    "    for row in query_result:\n",
    "        g.add_edge(row[0], row[1])\n",
    "\n",
    "    nx.write_gexf(g, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to generate the collaboration graph for \"workflow scheduling\" articles\n",
    "query = \"\"\"SELECT id \n",
    "FROM publications \n",
    "WHERE ((title like \"%schedul%\" or abstract like \"%schedul%\")\n",
    "AND (title like \"%workflow%\" or abstract like \"%workflow%\"))\n",
    "AND year between 2010 AND 2019\"\"\"\n",
    "file_name = \"collaboration-network-workflow-scheduling.gexf\"\n",
    "generate_network_for_paper_query(query, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to generate the collaboration graph for \"workflow formalism\" articles\n",
    "query = \"\"\"SELECT id \n",
    "FROM publications \n",
    "WHERE ((title like \"%formalism%\" or abstract like \"%formalism%\")\n",
    "AND (title like \"%workflow%\" or abstract like \"%workflow%\"))\n",
    "AND year between 2010 AND 2019\"\"\"\n",
    "file_name = \"collaboration-network-workflow-formalism.gexf\"\n",
    "generate_network_for_paper_query(query, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to generate the collaboration graph for \"resource provisioning/autoscaling\" articles\n",
    "query = \"\"\"SELECT id \n",
    "FROM publications \n",
    "WHERE ((title like \"%cloud%\" or abstract like \"%cloud%\")\n",
    "AND (title like \"%resource%\" or abstract like \"%resource%\")\n",
    "AND ((title like \"%provision%\" or abstract like \"%provision%\")\n",
    "OR (title like \"%autoscale%\" or abstract like \"%autoscale%\")))\n",
    "AND year between 2010 AND 2019\"\"\"\n",
    "file_name = \"collaboration-network-resource-provisioning.gexf\"\n",
    "generate_network_for_paper_query(query, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to generate the collaboration graph for \"cloud computing services\" articles\n",
    "query = \"\"\"SELECT id \n",
    "FROM publications \n",
    "WHERE ((title like \"%cloud%\" or abstract like \"%cloud%\")\n",
    "AND (title like \"%service%\" or abstract like \"%service%\")\n",
    "AND (title like \"%computing%\" or abstract like \"%computing%\"))\n",
    "AND year between 2010 AND 2019\"\"\"\n",
    "file_name = \"collaboration-network-cloud-computing-services.gexf\"\n",
    "generate_network_for_paper_query(query, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
