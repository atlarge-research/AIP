{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/lvs215/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/lvs215/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/lvs215/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import psycopg2\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\n",
    "    '../'))  # add the current module so that we can import the utils file\n",
    "from tools.utils import get_top_keywords_for_query, create_df_for_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(user=\"lvs215\",\n",
    "                        password=\"\",\n",
    "                        host=\"127.0.0.1\",\n",
    "                        port=\"12777\",\n",
    "                        database=\"aip\")\n",
    "start_year = 2011  # inclusive\n",
    "end_year = 2020  # inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get for each year, the top 100 keywords.\n",
    "num_keywords = 10\n",
    "# corpus_query = \"\"\"\n",
    "# SELECT * \n",
    "# FROM publications \n",
    "# WHERE year between ? and ?\n",
    "# and (lower(title) like '%workflow%' or lower(abstract) like '%workflow%') \n",
    "# and (lower(title) like '%schedul%' or lower(abstract) like '%schedul%')\n",
    "# \"\"\"\n",
    "corpus_query = \"\"\"\n",
    "SELECT * \n",
    "FROM publications \n",
    "WHERE year between %s and %s;\n",
    "\"\"\"\n",
    "corpus_df = create_df_for_query(conn, corpus_query, [start_year, end_year])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    # Workflow communities - 1\n",
    "    (\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM publications\n",
    "        WHERE year = %s\n",
    "        AND (title ILIKE %s OR abstract ILIKE %s)\n",
    "        AND (title ILIKE %s OR abstract ILIKE %s)\n",
    "        \"\"\",\n",
    "        \"workflow-community\",\n",
    "        \"collaboration-network-workflow-scheduling_aip.gexf\",\n",
    "        [\"%workflow%\", \"%workflow%\", '%schedul%', '%schedul%']\n",
    "    ),\n",
    "\n",
    "    # Workflow formalisms - 2\n",
    "    (\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM publications\n",
    "        WHERE year = %s\n",
    "        AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "        AND (\n",
    "            (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "            OR (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"workflow-formalism-community\",\n",
    "        \"collaboration-network-workflow-formalisms_aip.gexf\",\n",
    "        [\"%workflow%\", \"%workflow%\", \"%formalism%\", \"%formalism%\", \"%language%\",\n",
    "         \"%language%\"]\n",
    "    ),\n",
    "\n",
    "    # Workflow allocation - 3\n",
    "    (\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM publications\n",
    "        WHERE year = %s\n",
    "        AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "        AND (\n",
    "            (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "            OR (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "            OR (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"workflow-allocation-community\",\n",
    "        \"collaboration-network-workflow-allocation_aip.gexf\",\n",
    "        [\"%workflow%\", \"%workflow%\", \"%allocat%\", \"%allocat%\", \"%schedul%\",\n",
    "         \"%schedul%\", \"%plan%\", \"%plan%\"]\n",
    "    ),\n",
    "\n",
    "    # Resource provisioning communities - 4\n",
    "    (\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM publications\n",
    "        WHERE year = %s\n",
    "        AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "        AND (\n",
    "            lower(title) ILIKE %s OR lower(abstract) ILIKE %s\n",
    "            OR lower(title) ILIKE %s OR lower(abstract) ILIKE %s\n",
    "        )\n",
    "        \"\"\",\n",
    "        \"resource-provisioning-community\",\n",
    "        \"collaboration-network-resource-provisioning_aip.gexf\",\n",
    "        [\"%workflow%\", \"%workflow%\", \"%provision%\", \"%provision%\", \"%autoscal%\",\n",
    "         \"%autoscal%\"]\n",
    "    ),\n",
    "\n",
    "    # applications and services - 5\n",
    "    (\n",
    "        \"\"\"\n",
    "        SELECT *\n",
    "        FROM publications\n",
    "        WHERE year = %s\n",
    "        AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "        AND (lower(title) ILIKE %s OR lower(abstract) ILIKE %s)\n",
    "        \"\"\",\n",
    "        \"applications-and-services-community\",\n",
    "        \"collaboration-network-applications-and-services-community_aip.gexf\",\n",
    "        [\"%cloud%\", \"%cloud%\", \"%service%\", \"%service%\"]\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emerging_top_keywords_for_keywords_list(keywords_per_year):\n",
    "    # This cell outputs keywords that are amoung the top-{num_keywords} in the past (end_year - last_years, end_year] years\n",
    "    # that are not found in the block [start_year, end_year - last_years]\n",
    "\n",
    "    keywords_in_the_last_years = set()\n",
    "    last_years = 5\n",
    "    for year in range(end_year, end_year - last_years, -1):\n",
    "        for keyword in keywords_per_year[year]:\n",
    "            keywords_in_the_last_years.add(keyword)\n",
    "\n",
    "    keywords_in_the_remaining_years = set()\n",
    "    for year in range(end_year - last_years, start_year - 1, -1):\n",
    "        for keyword in keywords_per_year[year]:\n",
    "            keywords_in_the_remaining_years.add(keyword)\n",
    "\n",
    "    emerging_keywords = keywords_in_the_last_years - keywords_in_the_remaining_years\n",
    "    return [\"\\\\enquote{{{}}}\".format(i) for i in sorted(emerging_keywords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rising_top_keywords_for_keywords_list(keywords_per_year):\n",
    "    # This cell outputs keywords that have strictly risen in rank throughout the years in the top-{num_keywords}.\n",
    "\n",
    "    keyword_last_rank = dict()\n",
    "    seen_keywords = set()\n",
    "    emerging_keywords = set()\n",
    "\n",
    "    # Fill the dictionary with the initial year\n",
    "    for index in range(len(keywords_per_year[start_year])):\n",
    "        keyword = keywords_per_year[start_year][index]\n",
    "        keyword_last_rank[keyword] = index\n",
    "        seen_keywords.add(keyword)\n",
    "        emerging_keywords.add(keyword)\n",
    "\n",
    "    # for rank, word in keyword_last_rank.items():\n",
    "    #     print(rank, word)\n",
    "    # Now, we check each year's keywords. There can be four cases:\n",
    "    # 1. The keyword was also in last year's set. In this case the index (its rank) has to be higher or equal.\n",
    "    # 2. The keyword is not in keyword_last_rank _AND_ was never seen before, this means it can be an emerging field and should be added to the keyword_last_rank dictionary.\n",
    "    # 3. The keyword is not in keyword_last_rank _AND_ was seen before. This means it dropped throughout the years and should be removed.\n",
    "    # 4. A keyword was seen once and then never again, drop it if it was not encountered in the {end_year}.\n",
    "    for year in range(start_year + 1, end_year + 1):\n",
    "        this_years_rank = dict()\n",
    "        new_emerging_topics = set()  # Keep a clean set to automatically weed out keywords matching case 4\n",
    "        for index in range(len(keywords_per_year[year])):\n",
    "            keyword = keywords_per_year[year][index]\n",
    "\n",
    "            #         # For insight\n",
    "            #         if keyword == \"part\":\n",
    "            #             print(year, keyword, index)\n",
    "\n",
    "            # Case 1\n",
    "            if keyword in keyword_last_rank and keyword in emerging_keywords:\n",
    "                if index <= keyword_last_rank[\n",
    "                    keyword]:  # rank is lower, all is well\n",
    "                    this_years_rank[keyword] = index\n",
    "                    new_emerging_topics.add(keyword)\n",
    "            elif keyword not in seen_keywords:  # Case 2\n",
    "                this_years_rank[\n",
    "                    keyword] = index  # We can reuse keyword_last_rank since keywords are unique per year\n",
    "                new_emerging_topics.add(keyword)\n",
    "            else:  # Case 3 - this else statement can be deleted, but for completion's sake we left it in\n",
    "                if keyword in emerging_keywords:\n",
    "                    emerging_keywords.remove(keyword)\n",
    "\n",
    "            seen_keywords.add(\n",
    "                keyword)  # Always add the keyword to the seen keywords set.\n",
    "            keyword_last_rank = this_years_rank  # Set the last year's rank dict to this year, to be ready for the next potential loop iteration.\n",
    "            emerging_keywords = new_emerging_topics  # Since we swap at the end, keywords emerged in the last year are automatically kept.\n",
    "\n",
    "    ret = [\"\\\\enquote{{{}}}\".format(i) for i in emerging_keywords]\n",
    "\n",
    "    for word in emerging_keywords:\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            if word in keywords_per_year[year]:\n",
    "                print(word, year)\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflow-community\n",
      "\\enquote{based} \\enquote{deadline} \\enquote{makespan} \\enquote{model} \\enquote{multi} \\enquote{objective}\n",
      "model 2020\n",
      "workflow 2011\n",
      "workflow 2012\n",
      "workflow 2013\n",
      "workflow 2014\n",
      "workflow 2015\n",
      "workflow 2016\n",
      "workflow 2017\n",
      "workflow 2018\n",
      "workflow 2019\n",
      "workflow 2020\n",
      "multi 2020\n",
      "objective 2020\n",
      "based 2020\n",
      "\\enquote{model} \\enquote{workflow} \\enquote{multi} \\enquote{objective} \\enquote{based}\n",
      "workflow-formalism-community\n",
      "\\enquote{algorithm} \\enquote{analysis} \\enquote{cloud} \\enquote{computational} \\enquote{container} \\enquote{declaration} \\enquote{declarative} \\enquote{engine} \\enquote{framework} \\enquote{front} \\enquote{hypervolume} \\enquote{look} \\enquote{many} \\enquote{objective} \\enquote{optimization} \\enquote{optimizer} \\enquote{pareto} \\enquote{problem} \\enquote{red} \\enquote{reusable} \\enquote{scheduling} \\enquote{science} \\enquote{scripting} \\enquote{specification} \\enquote{sshfs} \\enquote{structure} \\enquote{support}\n",
      "problem 2020\n",
      "optimizer 2020\n",
      "hypervolume 2020\n",
      "pareto 2020\n",
      "algorithm 2020\n",
      "optimization 2020\n",
      "front 2020\n",
      "objective 2020\n",
      "\\enquote{problem} \\enquote{optimizer} \\enquote{hypervolume} \\enquote{pareto} \\enquote{algorithm} \\enquote{optimization} \\enquote{front} \\enquote{objective}\n",
      "workflow-allocation-community\n",
      "\\enquote{based} \\enquote{cost} \\enquote{deadline} \\enquote{multi} \\enquote{objective} \\enquote{proposed}\n",
      "objective 2020\n",
      "multi 2020\n",
      "workflow 2011\n",
      "workflow 2012\n",
      "workflow 2013\n",
      "workflow 2014\n",
      "workflow 2015\n",
      "workflow 2016\n",
      "workflow 2017\n",
      "workflow 2018\n",
      "workflow 2019\n",
      "workflow 2020\n",
      "\\enquote{objective} \\enquote{multi} \\enquote{workflow}\n",
      "resource-provisioning-community\n",
      "\\enquote{deadline} \\enquote{emerging} \\enquote{engineering} \\enquote{execution} \\enquote{hot} \\enquote{infrastructure} \\enquote{itrelated} \\enquote{model} \\enquote{processing} \\enquote{service} \\enquote{solution} \\enquote{well}\n",
      "hot 2020\n",
      "model 2020\n",
      "engineering 2020\n",
      "emerging 2020\n",
      "well 2020\n",
      "itrelated 2020\n",
      "\\enquote{hot} \\enquote{model} \\enquote{engineering} \\enquote{emerging} \\enquote{well} \\enquote{itrelated}\n",
      "applications-and-services-community\n",
      "\\enquote{cost} \\enquote{edge} \\enquote{performance}\n",
      "cloud 2011\n",
      "cloud 2012\n",
      "cloud 2013\n",
      "cloud 2014\n",
      "cloud 2015\n",
      "cloud 2016\n",
      "cloud 2017\n",
      "cloud 2018\n",
      "cloud 2019\n",
      "cloud 2020\n",
      "\\enquote{cloud}\n"
     ]
    }
   ],
   "source": [
    "for query, community, _, query_args in queries:\n",
    "    keywords_per_year = dict()\n",
    "    print(community)\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        args = [str(year), *query_args]\n",
    "        keywords = get_top_keywords_for_query(conn, corpus_df, query,\n",
    "                                              num_keywords,\n",
    "                                              article_query_params=args)\n",
    "        keywords_per_year[year] = keywords\n",
    "    print(*get_emerging_top_keywords_for_keywords_list(keywords_per_year))\n",
    "    print(*get_rising_top_keywords_for_keywords_list(keywords_per_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}